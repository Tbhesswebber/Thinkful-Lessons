{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read in a list of 2000+ positive words\n",
    "pos_words_loc = ('https://github.com/gurkpet/Thinkful-Lessons/blob/master/'\n",
    "             'Thinkful%202.2.7-Naive%20Bayes/Word%20Lists/positive-words.txt')\n",
    "pos_words_list = pd.read_html(pos_words_loc, skiprows=35)\n",
    "\n",
    "#clean up the read in by removing the first column of junk data\n",
    "for row in pos_words_list:\n",
    "   del row[0]    \n",
    "\n",
    "#convert list into dataframe\n",
    "pos_words = pd.DataFrame(pos_words_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_pos_words = list(pos_words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testaccuracy(target, data):\n",
    "    # Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb.fit(data, target)\n",
    "\n",
    "    pred = bnb.predict(data)\n",
    "\n",
    "    print('Out of {} predictions, {} were misclassified'.format(data.shape[0], (pred != target).sum()))\n",
    "    accuracy = (data.shape[0]-(pred != target).sum())/data.shape[0]\n",
    "    print('Thats a {0:.2} accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in amazon file\n",
    "amzn_file_loc = ('https://raw.githubusercontent.com/gurkpet/Thinkful-Lessons/master/'\n",
    "            'Thinkful%202.2.7-Naive%20Bayes/amazon_cells_labelled.txt')\n",
    "\n",
    "amzn_dat = pd.read_csv(amzn_file_loc, delimiter= '\\t', header=None)\n",
    "#rename column headers\n",
    "amzn_dat.columns = ['review', 'positive_review']\n",
    "amzn_target = amzn_dat['positive_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    for key in list_pos_words:\n",
    "        amzn_dat[str(key)] = amzn_dat.review.str.contains(str(key), case = False)\n",
    "    amzn_dat['positive_review'] = (amzn_dat['positive_review'] == 1)\n",
    "    data_amzn = amzn_dat[list_pos_words]\n",
    "    amzn_target = amzn_dat['positive_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 predictions, 166 were misclassified\n",
      "Thats a 0.83 accuracy\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "pred = bnb.predict(data)\n",
    "\n",
    "print('Out of {} predictions, {} were misclassified'.format(data.shape[0], (pred != target).sum()))\n",
    "accuracy = (data.shape[0]-(pred != target).sum())/data.shape[0]\n",
    "print('Thats a {0:.2} accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in amazon file\n",
    "yelp_file_loc = ('https://raw.githubusercontent.com/gurkpet/Thinkful-Lessons/master/'\n",
    "            'Thinkful%202.2.7-Naive%20Bayes/yelp_labelled.txt')\n",
    "\n",
    "yelp_dat = pd.read_csv(yelp_file_loc, delimiter= '\\t', header=None)\n",
    "#rename column headers\n",
    "yelp_dat.columns = ['review', 'positive_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in list_pos_words:\n",
    "    yelp_dat[str(key)] = yelp_dat.review.str.contains(str(key), case = False)\n",
    "yelp_dat['positive_review'] = (yelp_dat['positive_review'] == 1)\n",
    "\n",
    "data_yelp = yelp_dat[list_pos_words]\n",
    "yelp_target = yelp_dat['positive_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 predictions, 186 were misclassified\n",
      "Thats a 0.81 accuracy\n"
     ]
    }
   ],
   "source": [
    "testaccuracy(yelp_target, data_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in amazon file\n",
    "imdb_file_loc = ('https://raw.githubusercontent.com/gurkpet/Thinkful-Lessons/master/'\n",
    "            'Thinkful%202.2.7-Naive%20Bayes/imdb_labelled.txt')\n",
    "\n",
    "imdb_dat = pd.read_csv(imdb_file_loc, delimiter= '\\t', header=None)\n",
    "#rename column headers\n",
    "imdb_dat.columns = ['review', 'positive_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in list_pos_words:\n",
    "    imdb_dat[str(key)] = imdb_dat.review.str.contains(str(key), case = False)\n",
    "imdb_dat['positive_review'] = (imdb_dat['positive_review'] == 1)\n",
    "\n",
    "data_imdb = imdb_dat[list_pos_words]\n",
    "imdb_target = imdb_dat['positive_review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 748 predictions, 164 were misclassified\n",
      "Thats a 0.78 accuracy\n"
     ]
    }
   ],
   "source": [
    "testaccuracy(imdb_target, data_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
